---
title: "Análise de Regressão em Python"
author: 
  - Salvador Alves Ferreira Netto (2022040141)
  - Caique Izidoro Alvarenga
  - João Roberto Zuquim Filho
#abstract: ""
lang: pt
format: 
  pdf:
    toc: true
    fig-pos: "H"
    #toc-title: "Summary"
    toc-depth: 3
    #toc-location: right
    number-sections: true
    number-depth: 3
    documentclass: article
    fig-cap-location: bottom
    geometry:
      - top=3cm
      - left=3cm
      - right=2cm
      - bottom=2cm
execute:
  echo: false
  warning: false
  output: false
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf

from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
from statsmodels.graphics import utils
from statsmodels.compat.python import lzip
from scipy import stats
```

```{r}
library(palmerpenguins)
library(tidyverse)
library(knitr)
library(kableExtra)
library(reticulate)

data = penguins
```

```{python}
data = r.data
data = data.dropna()
data['year'] = data['year'].astype(str)
```

# Introdução

O banco de dados possui 333 linhas não nulas e 8 colunas
 
```{python}
head = data.head()
shape = data.shape
describe = data.describe()
groupby_species = data.groupby(['species'])['island'].value_counts().reset_index()
```

```{r tabela-head}
#| output: true
#| label: tbl-head
#| tbl-cap: "Visualização das 5 Primeiras Linhas do Banco de Dados"

kable(py$head, booktabs= T, linesep = "") %>% 
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down")) %>% 
  row_spec(0, bold= T)
```

```{r tabela-describe}
#| output: true
#| label: tbl-describe
#| tbl-cap: "Sumário do Banco de Dados"

kable(py$describe, booktabs= T, linesep = "") %>% 
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down")) %>% 
  row_spec(0, bold= T)
```

# Seleção de Variáveis

```{python grafico-pairplot}
#| output: true
#| label: fig-pairplot
#| fig-cap: "Relações em Pares por Especies"
#| fig-pos: "H"
#| layout-ncol: 2
#| fig-subcap: 
#|    - "Species"
#|    - "Sex"
#|    - "Island"
#|    - "Year"

g1 = sns.pairplot(data, hue="species", height= 1.5, diag_kind="hist")
plt.show()

g2 = sns.pairplot(data, hue="sex", height= 1.5, diag_kind="hist")
plt.show()

g3 = sns.pairplot(data, hue="island", height= 1.5, diag_kind="hist")
plt.show()

g4 = sns.pairplot(data, hue="year", height= 1.5, diag_kind="hist")
plt.show()
```
```{r tabela-groupby_species}
#| output: true
#| label: tbl-groupby_species
#| tbl-cap: "Quantidade de Espécies por Ilha"

kable(py$groupby_species, booktabs= T, linesep = "") %>% 
  row_spec(0, bold= T) %>% 
  collapse_rows(1, latex_hline = "major")
```

```{python grafico-heatmap}
#| output: true
#| label: fig-heatmap
#| fig-pos: "H"
#| fig-cap: "Correlações entre as Variáveis do Conjunto de Dados"

cor = data[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']].corr()

fig, ax = plt.subplots(figsize= (12, 10))
g = sns.heatmap(cor, annot= True, vmin= -1, vmax= 1, linewidth=.5, cmap='vlag', ax= ax)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.show()
```

# Ajuste do Modelo e Multicolinearidade

```{python}
#| output: true

modelo = smf.ols(
  formula= 'body_mass_g ~ flipper_length_mm + bill_depth_mm + bill_length_mm + sex',
  data= data
  ).fit()

print(modelo.summary())
```

```{python}
#| output: true
#| echo: true

X = modelo.model.exog
[variance_inflation_factor(X, i) for i in range(X.shape[1])]
```
```{python}
#| output: true
#| echo: true

modelo.bse
```

# Resíduos

```{python}
residuals = modelo.resid 
fitted_value = modelo.fittedvalues 
stand_resids = modelo.resid_pearson 
influence = modelo.get_influence() 
leverage = influence.hat_matrix_diag 
p = modelo.model.exog.shape[1]
n = modelo.model.exog.shape[0]
```

```{python grafico-residuos}
#| output: true
#| label: fig-residuos
#| fig-pos: "H"
#| fig-cap: "Análise Gráfica dos Resíduos"

fig, ax = plt.subplots(nrows=2, ncols=2, figsize= (10, 8)) 
  
# Residual vs Fitted Plot 
sns.residplot(x=fitted_value, y=residuals, ax=ax[0, 0], lowess= True) 
ax[0, 0].axhline(y=0, color='grey', linestyle='dashed') 
ax[0, 0].set_xlabel('Fitted Values') 
ax[0, 0].set_ylabel('Residuals') 
ax[0, 0].set_title('Residuals vs Fitted Fitted') 
  
# Normal Q-Q plot 
sm.qqplot(residuals, fit=True, line='45',ax=ax[0, 1]) 
ax[0, 1].set_title('Normal Q-Q') 
  
# Scale-Location Plot 
sns.residplot(x=fitted_value, y=residuals, ax=ax[1, 0], lowess= True) 
ax[1, 0].axhline(y=0, color='grey', linestyle='dashed') 
ax[1, 0].set_xlabel('Fitted values') 
ax[1, 0].set_ylabel('Sqrt(standardized residuals)') 
ax[1, 0].set_title('Scale-Location Plot') 
  
# Residual vs Leverage Plot 
sns.residplot(x=leverage, y=stand_resids, ax=ax[1, 1], lowess= True) 
ax[1, 1].axhline(y=0, color='grey', linestyle='dashed')
ax[1, 1].axvline(x= 2*p/n, color='red', linestyle='--')
ax[1, 1].axhline(y= stats.t.ppf(0.05/(2*n), n-p-1), color='red', linestyle='--')
ax[1, 1].axhline(y= -stats.t.ppf(0.05/(2*n), n-p-1), color='red', linestyle='--')
ax[1, 1].set_xlabel('Leverage') 
ax[1, 1].set_ylabel('Sqrt(standardized residuals)') 
ax[1, 1].set_title('Residuals vs Leverage Plot') 
  
  
plt.tight_layout() 
plt.show() 
```

```{python}
#| output: true

norm_test = stats.shapiro(residuals)
autocorr_errors = durbin_watson(residuals)

print('Shapiro Statistic: ', round(norm_test[0], 3))
print('Shapiro P-Value: ', round(norm_test[1], 3))
print('\nDurbin Watson Statistic:', autocorr_errors)
```

No gráfico de `Resíduos versus valores ajustados` e `Gráfico escala-locação`, podemos observar que a validade da suposição de linearidade existe no modelo, assim como a validade da suposição de homocedasticidade das variâncias. Isso é evidenciado pelo padrão relativamente aleatório dos resíduos em torno de zero, apesar de não ser perfeito.

O teste de *Durbin-Watson* para autocorrelação dos erros não mostra indícios de autocorrelação. Além disso, na figura `Normal Q-Q`, a verificação da suposição de normalidade dos erros é confirmada, e o teste de *Shapiro-Wilk* confirma esse resultado.

No gráfico `Resíduos versus Alavancagem`, observamos a presença de pontos de alavancagem, mas não identificamos pontos inconsistentes. Portanto, não atribuiremos atenção excessiva a esses pontos.

## Influência

```{python}
summ_df = influence.summary_frame().head()
```

```{r tabela-influencia}
#| output: true
#| label: tbl-influencia
#| tbl-cap: "Sumário das Observações Influentes"

kable(py$summ_df, booktabs= T, linesep = "") %>% 
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down")) %>% 
  row_spec(0, bold= T)
```

```{python}
#| output: true
#| echo: true

# DFFitS Threshold
summ_df[summ_df['dffits'] > 3*np.sqrt(p/(n-p))]['dffits']
```

```{python grafico-covratio}
#| output: true
#| label: fig-covratio
#| fig-cap: "COVRATIO"
#| fig-pos: "H"


# COVRATION Threshold
y = 1 - np.abs(influence.cov_ratio)
nobs = len(modelo.model.endog)
index = np.arange(nobs)
threshold = (3*p)/n
large_points = y > threshold
labels = modelo._results.model.data.row_labels
psize = 3 * np.ones(nobs)

# Gráfico
fig, ax = plt.subplots(figsize= (8, 6))
ax.scatter(index, y)
ax = utils.annotate_axes(np.where(large_points)[0], labels,
                                 lzip(index, y),
                                 lzip(-psize, psize), "large",
                                 ax)
font = {"fontsize": 12, "color": "black"}
ax.set_ylabel('|1-COVRATIO|', **font)
ax.set_xlabel("Observation", **font)
ax.set_title('COVRATIO', **font)
plt.show()
```

```{python grafico-hatcooks}
#| output: true
#| label: fig-hatcooks
#| fig-cap: "Medidas de Influência"
#| fig-pos: "H"
#| layout-ncol: 3
#| fig-subcap: 
#|    - "DF Beta (bill_depth_mm)"
#|    - "DF Beta (bill_length_mm)" 
#|    - "Leverage"
#|    - "Distância de Cooks"
#|    - "DFBeta (sex)"
#|    - "DFBeta (flipper_length_mm)"

# Leverage, Cooks and DFBetaS Threshold
influence.plot_index(y_var="hat_diag", threshold= (3*p)/n)
plt.show()
influence.plot_index(y_var="cooks", threshold= stats.f.ppf(0.5,p, n-p))
plt.show()
for i in range(1, p):
  influence.plot_index(y_var="dfbeta", idx= i, threshold= 1)
  plt.show()

```

  Em resumo, tanto as inspeções visuais quanto as análises estatísticas indicam que as observações não apresentam problemas significativos ou influências prejudiciais para a validade do nosso modelo.

## Regressão Parcial

```{python grafico-parcial}
#| output: true
#| label: fig-parcial
#| fig-cap: "Regressão Parcial"
#| fig-pos: "H"
#| layout: [[1, 1], [1]]
#| fig-subcap: 
#|    - "Bill Depth"
#|    - "Bill Length"
#|    - "Flipper Length"


# Regressão Parcial 'flipper_length_mm'
fig1 = plt.figure(figsize=(10, 8))
g1 = sm.graphics.plot_regress_exog(modelo, 'flipper_length_mm', fig= fig1)
plt.show()

# Regressão Parcial 'bill_depth_mm'
fig2 = plt.figure(figsize=(10, 8))
g2 = sm.graphics.plot_regress_exog(modelo, 'bill_depth_mm', fig= fig2)
plt.show()

# Regressão Parcial 'bill_depth_mm'
fig3 = plt.figure(figsize=(10, 8))
g3 = sm.graphics.plot_regress_exog(modelo, 'bill_length_mm', fig= fig3)
plt.show()
```

Ao analisar o @fig-parcial-3, notamos um padrão nulo na variável `bill_length_mm`, sugerindo que essa variável explicativa pode não ser necessária no modelo. Para confirmar essa suspeita, realizamos o teste t, e a variável `bill_length_mm` apresenta um valor p de $0.619$. Com base nesse resultado, temos evidências suficientes para considerar a remoção dessa variável do modelo.

```{python}
#| output: true
print(modelo.summary())
```
### Removendo 'bill_length_mm'

```{python}
#| output: true

modelo = smf.ols(
  formula= 'body_mass_g ~ flipper_length_mm + bill_depth_mm + sex',
  data= data
  ).fit()

print(modelo.summary())
```

```{python}
#| output: true
#| echo: true

X = modelo.model.exog
[variance_inflation_factor(X, i) for i in range(X.shape[1])]
```

```{python}
#| output: true
#| echo: true

modelo.bse
```
# Conclusões

